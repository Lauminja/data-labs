![Ironhack logo](https://i.imgur.com/1QgrNNw.png)

<<<<<<< HEAD
# Lab | Introduction to Natural Language Processing

## Introduction

In Module 1, if you remember, you learned about Text Mining. You also practiced how to create a Bag of Words using Python. That early introductory lesson discussed some concepts such as *tokenization*, *stemming*, and *lemmatization* which are typical techniques you can use in Natural Languages Processing(NLP). In this lab, you will learn how to use these techniques in action and conduct sentiment analysis (one type of NLP) on Twitter tweeets.

In this lab we cite some external resources for you to learn, which includes YouTube videos and web references. Soon you will graduate from this bootcamp and become a data analyst in practice. By then you will rely heavily on web resources to learn new knowledge. You will need to learn how to identify useful information, disgard irrelevant information, and evaluate the accuracy and timeliness of the information. This is the only way you will excel as a data expert.

### Objectives

* Learn about NLP.
* Install and test NLTK, a popular library created for NLP.
* Learn how to use NLTK to conduct sentiment analysis.

## Getting Started

Take Challenge 1-3 in order. Create Jupyter Notebooks as appropriate to code your answers.

## Deliverables

- Jupyter Notebooks containing your responses.

## Submission

* Submit the deliverables via git.

=======
# Lab | Natural Language Processing

## Introduction

In Challenge 1 of this lab we will walk you through how to prepare HTML data for NLP analysis. In Challenge 2 we will walk you through how to perform sentiment analysis on Tweets using NLTK.

## Getting Started

Complete `challenge-1.ipynb` and `challenge-2.ipynb` in the `your-code` directory. Follow the instructions and add your code and explanations as necessary. There are two YouTube videos in Challenge 2 that you can watch to better understand how to use NLTK to perform sentiment analysis.

## Deliverables

- `challenge-1.ipynb` and `challenge-2.ipynb` containing your responses.

## Submission

Upon completion, add your deliverables to git. Then commit git and push your branch to the remote.

## Resources

* [Matrix of document-term frequency](https://en.wikipedia.org/wiki/Document-term_matrix)

* NLTK stemming libraries
    * [Porter](https://www.nltk.org/_modules/nltk/stem/porter.html)
    * [Snowball](https://www.nltk.org/_modules/nltk/stem/snowball.html)
    * [Lancaster](https://www.nltk.org/_modules/nltk/stem/lancaster.html)

* [Word Net lemmatizer](https://www.nltk.org/_modules/nltk/stem/wordnet.html)

* [Sentiment Analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)

* [NLTK sentiment analysis package](https://www.nltk.org/api/nltk.sentiment.html)

* [Sentiment140 dataset with 1.6 million tweets on Kaggle](https://www.kaggle.com/kazanova/sentiment140)

* [NLTK `FreqDist`](https://www.nltk.org/api/nltk.html#module-nltk.probability)

* [NLTK building features (video)](https://www.youtube.com/watch?v=-vVskDsHcVc)

* [Converting words to Features with NLTK](https://pythonprogramming.net/words-as-features-nltk-tutorial/)

* [`nltk.NaiveBayesClassifier.train`](https://www.nltk.org/book/ch06.html)

* [NLTK training Naive Bayes (video)](https://www.youtube.com/watch?v=rISOsUaTrO4)

* [Naive Bayes Classifier with NLTK](https://pythonprogramming.net/naive-bayes-classifier-nltk-tutorial/)
>>>>>>> upstream/master
